import streamlit as st
import pandas as pd
import numpy as np
import pickle

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¸Ø§Ù‡Ø± Ø¨Ø±Ù†Ø§Ù…Ù‡
st.set_page_config(page_title="Epigenetic Age Predictor", page_icon="ğŸ§¬")

st.title("ğŸ§¬ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒâ€ŒØªØ±ÛŒÙ† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÚ¯Ø± Ø³Ù† Ø§Ù¾ÛŒâ€ŒÚ˜Ù†ØªÛŒÚ©")
st.write("Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ GSE40279 Ùˆ ÛµÛ°Û° Ø´Ø§Ø®Øµ Ø¨Ø±ØªØ± CpG Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ Ø§Ø³Øª.")

# Û±. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ Ø§Ø³Ú©ÛŒÙ„Ø± Ùˆ Ù„ÛŒØ³Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
@st.cache_resource
def load_model():
    with open("trained_model.pkl", "rb") as f:
        # ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ù…Ø§ Û³ ØªØ§ Ø¨Ø®Ø´ Ø¯Ø§Ø±Ù‡: Ù…Ø¯Ù„ØŒ Ø§Ø³Ú©ÛŒÙ„Ø± Ùˆ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        model, scaler, feature_names = pickle.load(f)
    return model, scaler, feature_names

try:
    model, scaler, feature_names = load_model()
    st.success("âœ… Ù…Ø¯Ù„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
except Exception as e:
    st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {e}")

# Û². Ø¨Ø®Ø´ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø±
uploaded_file = st.file_uploader("ÙØ§ÛŒÙ„ Ù…ØªÛŒÙ„Ø§Ø³ÛŒÙˆÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (CSV ÛŒØ§ TXT)", type=["csv", "txt"])

if uploaded_file is not None:
    try:
        # Ø®ÙˆÙ†Ø¯Ù† ÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±
        user_data = pd.read_csv(uploaded_file, index_col=0)
        
        st.info("Ø¯Ø± Ø­Ø§Ù„ ØªØ·Ø¨ÛŒÙ‚ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ø´Ù…Ø§ Ø¨Ø§ Ù…Ø¯Ù„ Ù…Ø±Ø¬Ø¹...")

        # Û³. Ø¨Ø®Ø´ Ø­ÛŒØ§ØªÛŒ: ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        # Ú†Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ø¯ÙˆÙ… ÛŒÚ©ÛŒ Ø§Ø² Ø§ÙˆÙ† ÛµÛ°Û° ØªØ§ Ø³ØªÙˆÙ† ØªÙˆÛŒ ÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø± Ù‡Ø³Øª
        available_features = [f for f in feature_names if f in user_data.columns]
        missing_features = [f for f in feature_names if f not in user_data.columns]

        if len(available_features) < len(feature_names) * 0.8:
            st.warning(f"âš ï¸ ØªÙˆØ¬Ù‡: ÙØ§ÛŒÙ„ Ø´Ù…Ø§ ÙÙ‚Ø· {len(available_features)} Ù…ÙˆØ±Ø¯ Ø§Ø² ÛµÛ°Û° Ø´Ø§Ø®Øµ Ù„Ø§Ø²Ù… Ø±Ø§ Ø¯Ø§Ø±Ø¯. Ø¯Ù‚Øª Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ø§Ù‡Ø´ ÛŒØ§Ø¨Ø¯.")
        
        # Ù¾Ø± Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØºØ§ÛŒØ¨ Ø¨Ø§ Ø¹Ø¯Ø¯ ØµÙØ± (ÛŒØ§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†) Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        input_df = user_data.reindex(columns=feature_names, fill_value=0)

        # Û´. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ø³Ú©ÛŒÙ„Ø± Ù…Ø¯Ù„ Ø§ØµÙ„ÛŒ
        input_scaled = scaler.transform(input_df)
        
        # Ø­Ø¯Ø³ Ø²Ø¯Ù† Ø³Ù†
        prediction = model.predict(input_scaled)

        # Ûµ. Ù†Ù…Ø§ÛŒØ´ Ù†ØªÛŒØ¬Ù‡ Ø¨Ø§ Ú©Ù„Ø§Ø³ Ø¬Ù‡Ø§Ù†ÛŒ
        st.balloons()
        st.subheader("Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒÙˆÙ„ÙˆÚ˜ÛŒÚ©ÛŒ:")
        cols = st.columns(2)
        cols[0].metric("Ø³Ù† Ø§Ù¾ÛŒâ€ŒÚ˜Ù†ØªÛŒÚ© ØªØ®Ù…ÛŒÙ†ÛŒ", f"{prediction[0]:.1f} Ø³Ø§Ù„")
        cols[1].metric("ØªØ¹Ø¯Ø§Ø¯ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡", f"{len(available_features)} CpG")

        st.progress(min(int(prediction[0]), 100))
        st.write("---")
        st.caption("Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÛŒÙ… ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ù…Ø§ÛŒÚ©Ù„ Ù„Ø§Ø³ØªÚ¯Ø§Ø±ØªÙ† - ØªÙˆØ³Ø¹Ù‡ ÛŒØ§ÙØªÙ‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ NCBI")

    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„: {e}")
